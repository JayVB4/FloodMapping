{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef63b65b-5cd2-4b66-96bf-f5d4b49f7428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Principal Components:\n",
      "          PC1       PC2       PC3       PC4       PC5       PC6       PC7  \\\n",
      "0   5.955599 -1.610213  0.883354 -0.153376 -0.057685  0.001574 -0.002905   \n",
      "1   4.431454 -0.087854 -0.750800  0.819901  0.067486 -0.075210  0.014356   \n",
      "2   2.760967  0.278819 -0.732507 -0.551815  0.015428  0.225583 -0.038764   \n",
      "3   1.233078  1.174735 -0.109612 -0.499891  0.249220 -0.132924  0.025194   \n",
      "4  -0.419574  0.561250  0.024690 -0.261386 -0.200804 -0.234547  0.059902   \n",
      "5  -0.280933  1.638931  0.384315  0.258440 -0.482827  0.057538 -0.028654   \n",
      "6  -1.468185  0.662546  0.391361  0.201716  0.141799  0.092972 -0.071074   \n",
      "7  -2.253204  0.165925  0.323715  0.188131  0.263822  0.110765  0.041463   \n",
      "8  -2.817734 -0.323170  0.146190  0.110344  0.263128  0.060864  0.093380   \n",
      "9  -3.389953 -0.939520 -0.125689 -0.017877  0.124395 -0.164964 -0.137156   \n",
      "10 -3.751515 -1.521448 -0.435017 -0.094187 -0.383963  0.058349  0.044258   \n",
      "\n",
      "         PC8       PC9      PC10          PC11  \n",
      "0  -0.006908  0.000626 -0.000221 -9.040992e-17  \n",
      "1   0.000684  0.003035  0.000301 -9.040992e-17  \n",
      "2   0.021813 -0.015716 -0.000639 -9.040992e-17  \n",
      "3  -0.060154  0.025964 -0.000453 -9.040992e-17  \n",
      "4   0.080568 -0.015284  0.002058 -9.040992e-17  \n",
      "5  -0.047510 -0.007238 -0.003505 -9.040992e-17  \n",
      "6   0.038962  0.014099  0.010534 -9.040992e-17  \n",
      "7   0.058072  0.011064 -0.009979 -9.040992e-17  \n",
      "8  -0.057881 -0.028457  0.003854 -9.040992e-17  \n",
      "9  -0.017273 -0.011448 -0.003566 -9.040992e-17  \n",
      "10 -0.010374  0.023354  0.001617 -9.040992e-17  \n",
      "Explained Variance:\n",
      " [0.870 0.089 0.021 0.012 0.006 0.002 0.000 0.000 0.000 0.000 0.000]\n",
      "test\n",
      " [[0.870 0.179 0.042 0.037 0.022 0.008 0.002 0.001 0.000 0.000 0.000]\n",
      " [0.435 0.089 0.042 0.037 0.017 0.006 0.002 0.001 0.000 0.000 0.000]\n",
      " [0.435 0.045 0.021 0.025 0.017 0.006 0.001 0.001 0.000 0.000 0.000]\n",
      " [0.290 0.030 0.010 0.012 0.011 0.005 0.001 0.001 0.000 0.000 0.000]\n",
      " [0.217 0.030 0.007 0.006 0.005 0.003 0.001 0.001 0.000 0.000 0.000]\n",
      " [0.174 0.022 0.005 0.004 0.003 0.002 0.001 0.001 0.000 0.000 0.000]\n",
      " [0.174 0.018 0.005 0.004 0.003 0.001 0.000 0.000 0.000 0.000 0.000]\n",
      " [0.145 0.015 0.004 0.003 0.002 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      " [0.124 0.013 0.004 0.003 0.001 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      " [0.109 0.011 0.003 0.002 0.001 0.000 0.000 0.000 0.000 0.000 0.000]\n",
      " [0.109 0.011 0.003 0.002 0.001 0.000 0.000 0.000 0.000 0.000 0.000]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import plotly.express as px\n",
    "RI = np.array([0,0,0.58,0.90,1.12,1.24,1.32,1.41,1.45,1.49,1.51,1.48,1.56,1.57,1.58])\n",
    "\n",
    "mainarr = np.array([[1   ,2   ,2   ,3   ,4   ,5   ,5   ,6   ,7   ,8   ,8],\n",
    "                   [1/2 ,1   ,2   ,3   ,3   ,4   ,5   ,6   ,7   ,8   ,8],\n",
    "                   [1/2 ,1/2 ,1   ,2   ,3   ,4   ,4   ,5   ,6   ,7   ,7],\n",
    "                   [1/3 ,1/3 ,1/2 ,1   ,2   ,3   ,3   ,4   ,5   ,7   ,8],\n",
    "                   [1/4 ,1/3 ,1/3 ,1/2 ,1   ,2   ,2   ,3   ,4   ,5   ,6],\n",
    "                   [1/5 ,1/4 ,1/4 ,1/3 ,1/2 ,1   ,2   ,4   ,5   ,7   ,7],\n",
    "                   [1/5 ,1/5 ,1/4 ,1/3 ,1/2 ,1/2 ,1   ,2   ,3   ,5   ,6],\n",
    "                   [1/6 ,1/6 ,1/5 ,1/4 ,1/3 ,1/4 ,1/2 ,1   ,2   ,4   ,5],\n",
    "                   [1/7 ,1/7 ,1/6 ,1/5 ,1/4 ,1/5 ,1/3 ,1/2 ,1   ,3   ,4],\n",
    "                   [1/8 ,1/8 ,1/7 ,1/7 ,1/5 ,1/7 ,1/5 ,1/4 ,1/3 ,1   ,3],\n",
    "                   [1/8 ,1/8 ,1/7 ,1/8 ,1/6 ,1/7 ,1/6 ,1/5 ,1/4 ,1/3 ,1]]\n",
    "                  )\n",
    "\n",
    "\n",
    "# Sample data for demonstration\n",
    "data = pd.DataFrame([[1, 2, 2, 3, 4, 5, 5, 6, 7, 8, 8],\n",
    "                     [1/2, 1, 2, 3, 3, 4, 5, 6, 7, 8, 8],\n",
    "                     [1/2, 1/2, 1, 2, 3, 4, 4, 5, 6, 7, 7],\n",
    "                     [1/3, 1/3, 1/2, 1, 2, 3, 3, 4, 5, 7, 8],\n",
    "                     [1/4, 1/3, 1/3, 1/2, 1, 2, 2, 3, 4, 5, 6],\n",
    "                     [1/5, 1/4, 1/4, 1/3, 1/2, 1, 2, 4, 5, 7, 7],\n",
    "                     [1/5, 1/5, 1/4, 1/3, 1/2, 1/2, 1, 2, 3, 5, 6],\n",
    "                     [1/6, 1/6, 1/5, 1/4, 1/3, 1/4, 1/2, 1, 2, 4, 5],\n",
    "                     [1/7, 1/7, 1/6, 1/5, 1/4, 1/5, 1/3, 1/2, 1, 3, 4],\n",
    "                     [1/8, 1/8, 1/7, 1/7, 1/5, 1/7, 1/5, 1/4, 1/3, 1, 3],\n",
    "                     [1/8, 1/8, 1/7, 1/8, 1/6, 1/7, 1/6, 1/5, 1/4, 1/3, 1]])\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(mainarr)\n",
    "\n",
    "# Perform PCA\n",
    "pca = PCA()  # Adjust number of components as needed\n",
    "principal_components = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Create a DataFrame with the principal components\n",
    "pc_df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7', 'PC8', 'PC9', 'PC10', 'PC11'])\n",
    "\n",
    "# Explained variance\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "# Output results\n",
    "print(\"Principal Components:\\n\", pc_df)\n",
    "print(\"Explained Variance:\\n\", explained_variance)\n",
    "\n",
    "for i in range(0,mainarr[0].size):\n",
    "    mainarr[i] = np.multiply(mainarr[i],explained_variance)\n",
    "print(\"test\\n\",mainarr.round(4))\n",
    "\n",
    "\n",
    "n = mainarr[0].size\n",
    "# float_formatter = \"{:.3f}\".format\n",
    "# np.set_printoptions(formatter={'float_kind':float_formatter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17ca95a3-6b54-4d2d-ba3f-368e210d9f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteriaweights = []  \n",
    "def criteriaWeights(mainarr):\n",
    "    n = mainarr[0].size\n",
    "    colsum = mainarr.sum(axis=0)\n",
    "    # normalized form \n",
    "    i=0\n",
    "    \n",
    "    normalizedform = np.array(mainarr)\n",
    "    for p in mainarr:\n",
    "        normalizedform[i] = np.divide(mainarr[i] , colsum)\n",
    "        i+=1\n",
    "    \n",
    "    # finding criteriaweights\n",
    "    criteriaweights = normalizedform.sum(axis=1)/n\n",
    "\n",
    "    #data consistency checking started\n",
    "\n",
    "    i=0\n",
    "    c1 = np.array(mainarr)\n",
    "    for p in mainarr:\n",
    "        c1[i] = np.multiply(mainarr[i] , criteriaweights)\n",
    "        i=i+1\n",
    "\n",
    "    weightedsum = c1.sum(axis=1)\n",
    "\n",
    "    #weightedsum upon criteria weight = naipata\n",
    "    naipata = np.divide(weightedsum,criteriaweights)\n",
    "    lamda = naipata.sum(axis=0)/n\n",
    "    lamda=round(lamda, 4) \n",
    "        #now we find consistency index CI\n",
    "    CI = (lamda-n)/(n-1)\n",
    "    CI = round(CI,5)\n",
    "    #cr is consistency ratio = consistency index upon random index\n",
    "    CR = CI / RI[n-1]\n",
    "    print(\"cr \",CR)\n",
    "    \n",
    "    if(CR<0.10):\n",
    "        print(\"VALUES ARE CONSISTENT - go ahead\")\n",
    "        return criteriaweights\n",
    "    else:\n",
    "        print(\"criteria weights are not consistent reEnter the values\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b44e7fed-e6ff-4974-98f6-16ae99054cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subcriteria\n",
    "df =pd.read_csv(\"WesternGhatData/1Elevation.csv\")\n",
    "elevation= df.to_numpy()\n",
    "\n",
    "df =pd.read_csv(\"WesternGhatData/2Slope.csv\")\n",
    "slope= df.to_numpy()\n",
    "\n",
    "df =pd.read_csv(\"WesternGhatData/3DistancefromRiver.csv\")\n",
    "river= df.to_numpy()\n",
    "\n",
    "df =pd.read_csv(\"WesternGhatData/4Drainage.csv\")\n",
    "drainage= df.to_numpy()\n",
    "\n",
    "df =pd.read_csv(\"WesternGhatData/5FlowAccumulation.csv\")\n",
    "flow= df.to_numpy()\n",
    "\n",
    "df =pd.read_csv(\"WesternGhatData/6TWI.csv\")\n",
    "twi= df.to_numpy()\n",
    "\n",
    "df =pd.read_csv(\"WesternGhatData/7Rainfall.csv\")\n",
    "rainfall= df.to_numpy()\n",
    "\n",
    "df =pd.read_csv(\"WesternGhatData/8Landuse.csv\")\n",
    "landuse= df.to_numpy()\n",
    "\n",
    "df =pd.read_csv(\"WesternGhatData/9SoilTexture.csv\")\n",
    "soil= df.to_numpy()\n",
    "\n",
    "df =pd.read_csv(\"WesternGhatData/10TRI.csv\")\n",
    "tri= df.to_numpy()\n",
    "\n",
    "df =pd.read_csv(\"WesternGhatData/11Geology.csv\")\n",
    "geology= df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5501bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cr  -0.6606158940397351\n",
      "VALUES ARE CONSISTENT - go ahead\n",
      "[0.236 0.195 0.152 0.112 0.078 0.075 0.053 0.038 0.028 0.019 0.014]\n"
     ]
    }
   ],
   "source": [
    "print(criteriaWeights(mainarr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bada257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cr  0.021589285714285714\n",
      "VALUES ARE CONSISTENT - go ahead\n",
      "[0.518 0.218 0.139 0.084 0.041] elevation\n",
      "\n",
      "\n",
      "cr  0.029464285714285714\n",
      "VALUES ARE CONSISTENT - go ahead\n",
      "[0.499 0.276 0.113 0.070 0.043] slope\n",
      "\n",
      "\n",
      "cr  0.042142857142857135\n",
      "VALUES ARE CONSISTENT - go ahead\n",
      "[0.400 0.258 0.197 0.102 0.043] river\n",
      "\n",
      "\n",
      "cr  0.013455357142857142\n",
      "VALUES ARE CONSISTENT - go ahead\n",
      "[0.433 0.262 0.164 0.089 0.052] drainage\n",
      "\n",
      "\n",
      "cr  0.01138392857142857\n",
      "VALUES ARE CONSISTENT - go ahead\n",
      "[0.423 0.287 0.151 0.088 0.050] flow\n",
      "\n",
      "\n",
      "cr  0.04176785714285714\n",
      "VALUES ARE CONSISTENT - go ahead\n",
      "[0.421 0.253 0.192 0.090 0.045] twi\n",
      "\n",
      "\n",
      "cr  0.015241071428571425\n",
      "VALUES ARE CONSISTENT - go ahead\n",
      "[0.416 0.262 0.161 0.099 0.062] rainfall\n",
      "\n",
      "\n",
      "cr  0.01987096774193548\n",
      "VALUES ARE CONSISTENT - go ahead\n",
      "[0.379 0.249 0.160 0.102 0.065 0.043] landuse\n",
      "\n",
      "\n",
      "cr  0.02862121212121212\n",
      "VALUES ARE CONSISTENT - go ahead\n",
      "[0.331 0.231 0.152 0.123 0.081 0.050 0.033] soil\n",
      "\n",
      "\n",
      "cr  0.059125\n",
      "VALUES ARE CONSISTENT - go ahead\n",
      "[0.398 0.300 0.171 0.093 0.037] tri\n",
      "\n",
      "\n",
      "cr  0.007931034482758621\n",
      "VALUES ARE CONSISTENT - go ahead\n",
      "[0.539 0.297 0.164] geology\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(criteriaWeights(elevation),\"elevation\\n\\n\")\n",
    "print(criteriaWeights(slope),\"slope\\n\\n\")\n",
    "print(criteriaWeights(river),\"river\\n\\n\")\n",
    "print(criteriaWeights(drainage),\"drainage\\n\\n\")\n",
    "print(criteriaWeights(flow),\"flow\\n\\n\")\n",
    "print(criteriaWeights(twi),\"twi\\n\\n\")\n",
    "print(criteriaWeights(rainfall),\"rainfall\\n\\n\")\n",
    "print(criteriaWeights(landuse),\"landuse\\n\\n\")\n",
    "print(criteriaWeights(soil),\"soil\\n\\n\")\n",
    "print(criteriaWeights(tri),\"tri\\n\\n\")\n",
    "print(criteriaWeights(geology),\"geology\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0deaaef-63c3-4dbc-8baf-fe9997d956e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function made\n",
    "def bene(arr):\n",
    "    num=0\n",
    "    while num<n:\n",
    "        ite=0\n",
    "        max=np.max(arr[num])\n",
    "        min=np.min(arr[num])\n",
    "        for i in arr[num] :\n",
    "            if(num != 0):\n",
    "                arr[num][ite]=i/max\n",
    "            else:\n",
    "                arr[num][ite]=min/i\n",
    "            ite+=1\n",
    "        num+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ed281b5-c638-4ff0-8a23-868d44b186ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 4 is out of bounds for axis 0 with size 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m Tla \u001b[38;5;241m=\u001b[39m Tla\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# function called\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mbene\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTla\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m Tla \u001b[38;5;241m=\u001b[39m Tla\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(Tla)\n",
      "Cell \u001b[1;32mIn[13], line 6\u001b[0m, in \u001b[0;36mbene\u001b[1;34m(arr)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m num\u001b[38;5;241m<\u001b[39mn:\n\u001b[0;32m      5\u001b[0m     ite\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmax(\u001b[43marr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mmin(arr[num])\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m arr[num] :\n",
      "\u001b[1;31mIndexError\u001b[0m: index 4 is out of bounds for axis 0 with size 4"
     ]
    }
   ],
   "source": [
    "#Tla transpose list array   ctla copy of tla\n",
    "listarray = np.array([[250,16,12,5],[200,16,8,3],[300,32,16,4],[275,32,8,4],[225,16,16,2]])\n",
    "print(\"\\n\")\n",
    "Tla = listarray.T\n",
    "Tla = Tla.astype('float64') \n",
    "\n",
    "# function called\n",
    "bene(Tla)\n",
    "Tla = Tla.T\n",
    "print(Tla)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae0fe8d-8d7b-45a8-b8f5-fb1de9d4a6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = 0\n",
    "for i in Tla:\n",
    "    Tla[cw] = np.multiply(Tla[cw],criteriaweights)\n",
    "    cw+=1\n",
    "print(Tla)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043defb8-5dbe-4b0c-b31f-726eb8525a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weighted normalized decision matrix\n",
    "\n",
    "# out_arr = np.multiply(in_arr1, in_arr2) ye galat hai for what i am doin     \n",
    "\n",
    "# out_arr=np.array(in_arr1)*np.array(in_arr2) this is right\n",
    "\n",
    "# wndm = np.array(Tla)*np.array(cw)\n",
    "# print(wndm)\n",
    "#now this is according to the other video example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5c4f4f-5146-473d-8a4c-4aeced07af77",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfscore = Tla.sum(axis=1)\n",
    "print (perfscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af7a24a-7e77-4268-820e-d391b777df28",
   "metadata": {},
   "outputs": [],
   "source": [
    "rankArr = np.array(perfscore)\n",
    "ranks = perfscore.size\n",
    "for score in rankArr :\n",
    "    rankArr[rankArr.argmin()]=ranks\n",
    "    ranks-=1\n",
    "print(rankArr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46ffcd7-27d7-4987-85c3-207517baa90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalarr = np.column_stack([listarray,rankArr])\n",
    "print(finalarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd06e34-de9c-42f5-a63d-413534d55e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalarr = finalarr[finalarr[:,finalarr[0].size-1].argsort()]\n",
    "print(finalarr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cea1e9-c52f-4229-864e-dcd8737f1679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f7f419-5f79-4d1a-ac46-c944d108f906",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e506e800-47c4-459d-912e-512afbe13f70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0887fd68-e540-4965-84fe-a618fa2b7bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
